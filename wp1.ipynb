{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wp1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhisheksaxena1998/packages/blob/master/wp1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqQdOqb5Yy9u",
        "colab_type": "code",
        "outputId": "3b9d2905-64ca-45e0-c35a-3865b8aae17a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "df=pd.read_csv(\"ner_dataset.csv\",encoding='latin1')\n",
        "df\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795564</th>\n",
              "      <td>NaN</td>\n",
              "      <td>DC</td>\n",
              "      <td>NNP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795565</th>\n",
              "      <td>NaN</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795566</th>\n",
              "      <td>NaN</td>\n",
              "      <td>has</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795567</th>\n",
              "      <td>NaN</td>\n",
              "      <td>partnered</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795568</th>\n",
              "      <td>NaN</td>\n",
              "      <td>with</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>795569 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Sentence #           Word  POS  Tag\n",
              "0       Sentence: 1      Thousands  NNS    O\n",
              "1               NaN             of   IN    O\n",
              "2               NaN  demonstrators  NNS    O\n",
              "3               NaN           have  VBP    O\n",
              "4               NaN        marched  VBN    O\n",
              "...             ...            ...  ...  ...\n",
              "795564          NaN             DC  NNP    O\n",
              "795565          NaN              ,    ,    O\n",
              "795566          NaN            has  VBZ    O\n",
              "795567          NaN      partnered  VBN    O\n",
              "795568          NaN           with  NaN  NaN\n",
              "\n",
              "[795569 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juWgcK1upTgL",
        "colab_type": "code",
        "outputId": "03203e4d-ff82-4f53-c9fd-7ef137e096db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xduZns40cOdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_df=df['Word']\n",
        "y_df=df['Tag']\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, random_state=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6E2vkAJdVxh",
        "colab_type": "code",
        "outputId": "516db4cc-beb3-4c3d-8c84-7c96dd0b6dcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
        "vect = TfidfVectorizer(min_df=5).fit(X_train)\n",
        "len(vect.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8549"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U47BEIuudXOD",
        "colab_type": "code",
        "outputId": "9a667ed0-03d7-4103-f6b4-1ad90088840f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "X_train_vectorized = vect.transform(X_train)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import preprocessing\n",
        "\n",
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "    lb = preprocessing.LabelBinarizer()\n",
        "    lb.fit(y_test)\n",
        "    y_test = lb.transform(y_test)\n",
        "    y_pred = lb.transform(y_pred)\n",
        "    return roc_auc_score(y_test, y_pred, average=average)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "predictions = model.predict(vect.transform(X_test))\n",
        "\n",
        "print('AUC: ', multiclass_roc_auc_score(y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.6662988290426365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTCCXIB7dgc9",
        "colab_type": "code",
        "outputId": "f87290fa-7911-4f89-a25a-c1157f64ba5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(model.predict(vect.transform(['america'])))#####add test subject\n",
        "print(model.predict(vect.transform(['british'])))#####add test subject\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I-geo']\n",
            "['B-gpe']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdzjZ9nyfInj",
        "colab_type": "code",
        "outputId": "bfaf7c16-b29d-42b9-cd97-8d5cc09afd35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "sentence=input(\"Enter a sentence : \")\n",
        "ne=[]\n",
        "for i in sentence.split(' '):\n",
        "  ne.append(model.predict(vect.transform([i])))\n",
        "  #print (model.predict(vect.transform([i])))  \n",
        "print (ne)  \n",
        "print (ne[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a sentence : british britain tainy selena \n",
            "[array(['B-gpe'], dtype=object), array(['B-geo'], dtype=object), array(['O'], dtype=object), array(['O'], dtype=object), array(['O'], dtype=object)]\n",
            "['B-gpe']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZu95gU9rvx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sen=input(\"Enter a sentence : \")\n",
        "ne=[]\n",
        "for i in sen.split(' '):\n",
        "  ne.append(model.predict(vect.transform([i])))\n",
        "  #print (model.predict(vect.transform([i])))  \n",
        "print (ne)  \n",
        "print (ne[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFIa3HuiqKoD",
        "colab_type": "code",
        "outputId": "b273346f-03fa-491f-9a1b-8c134cf71129",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ne.remove('O')\n",
        "print (ne)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array(['B-gpe'], dtype=object), array(['B-geo'], dtype=object)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ03rqE-h44s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize \n",
        "import warnings \n",
        "\n",
        "warnings.filterwarnings(action = 'ignore') \n",
        "\n",
        "import gensim \n",
        "from gensim.models import Word2Vec "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVFuVIz8k_lH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = df['Word']\n",
        "for i in sample:\n",
        "  with open ('ncorpus.txt','a') as res:\n",
        "    res.write(i+' ')\n",
        "    \n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEs09Oinltr-",
        "colab_type": "code",
        "outputId": "c2425b65-c554-4ed0-f7f0-7737d43e3e48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample = open(\"ncorpus.txt\", \"r\") \n",
        "s = sample.read() \n",
        "\n",
        "# Replaces escape character with space \n",
        "f = s.replace(\"\\n\", \" \") \n",
        "\n",
        "data = [] \n",
        "\n",
        "# iterate through each sentence in the file \n",
        "for i in sent_tokenize(f): \n",
        "\ttemp = [] \n",
        "\t\n",
        "\t# tokenize the sentence into words \n",
        "\tfor j in word_tokenize(i): \n",
        "\t\ttemp.append(j.lower()) \n",
        "\n",
        "\tdata.append(temp) \n",
        "\n",
        "# Create CBOW model \n",
        "model1 = gensim.models.Word2Vec(data,min_count = 1, size = 100, window = 5) \n",
        "\n",
        "# Print results \n",
        "print(\"Cosine similarity between 'alice' \" + \"and 'wonderland' - CBOW : \", model1.similarity('london', 'nation')) \n",
        "\n",
        "#print(\"Cosine similarity between 'alice' \" + \"and 'machines' - CBOW : \", model1.similarity('President', 'obama')) \n",
        "\n",
        "# Create Skip Gram model \n",
        "#model2 = gensim.models.Word2Vec(data, min_count = 1, size = 100, window = 5, sg = 1) \n",
        "\n",
        "# Print results \n",
        "#print(\"Cosine similarity between 'alice' \" + \"and 'wonderland' - Skip Gram : \", model2.similarity('modi', 'country')) \n",
        "\n",
        "#print(\"Cosine similarity between 'alice' \" + \"and 'machines' - Skip Gram : \", model2.similarity('modi', 'country')) \n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'alice' and 'wonderland' - CBOW :  0.26406616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewdasU6tyPeg",
        "colab_type": "code",
        "outputId": "086adb86-6016-4c99-fb00-3cd9bdcb0a37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "print (model1)\n",
        "\n",
        "print (data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMMdTNH-pL1o",
        "colab_type": "code",
        "outputId": "c994a9ed-bf10-4672-b378-873c78f4d36c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Cosine similarity between 'london' \" + \"and 'nation' - CBOW : \", model1.similarity('london', 'nation')) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'london' and 'nation' - CBOW :  -0.0876862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDzuhT1R-LDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in data:\n",
        "    for j in i:\n",
        "      max=model1.similarity('london',j)\n",
        "      print(f\"Cosine similarity between 'london' and {j} - CBOW : \", model1.similarity('london',j)) \n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f11RrA-_RH5",
        "colab_type": "code",
        "outputId": "ca6bb38e-9609-4aad-c6e9-54b81bd577fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "lista=[]\n",
        "listb=[]\n",
        "listc=[]\n",
        "for i in data:\n",
        "    for j in i:\n",
        "            lista.append('london')\n",
        "            listb.append(j)\n",
        "            listc.append(model1.similarity('london', j))\n",
        "for i in range(len(listc)):\n",
        "    max=listc[0]\n",
        "    if max<listc[i]:\n",
        "        max=listc[i]\n",
        "        pos=i\n",
        "print (pos)   \n",
        "print (listc[pos])  \n",
        "print (f\"Maximum similiarity is found in 'london' and  {listb[i]}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1048785\n",
            "0.63151145\n",
            "Maximum similiarity is found in 'london' and  attack\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF81g7To_g8D",
        "colab_type": "code",
        "outputId": "b60bc769-cc2b-4baa-f1ec-9e8256182ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "lista=[]\n",
        "listb=[]\n",
        "listc=[]\n",
        "for i in data:\n",
        "    for j in i:\n",
        "            lista.append('europe')\n",
        "            listb.append(j)\n",
        "            listc.append(model1.similarity('europe', j))\n",
        "for i in range(len(listc)):\n",
        "    max=listc[0]\n",
        "    if max<listc[i]:\n",
        "        max=listc[i]\n",
        "        pos=i\n",
        "print (pos)   \n",
        "print (listc[pos])  \n",
        "print (f\"Maximum similiarity is found in 'europe' and  {listb[i]}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1048784\n",
            "0.40427488\n",
            "Maximum similiarity is found in 'europe' and  attack\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WShQ-MZ2UOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xj2hNFuBO_u",
        "colab_type": "code",
        "outputId": "74def001-82b6-432f-917e-38537c724427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import numpy as numpy\n",
        "list3=[]\n",
        "list4=[]\n",
        "list5=[]\n",
        "for i in data:\n",
        "    for j in i:\n",
        "            list3.append('america')\n",
        "            list4.append(j)\n",
        "            list5.append(model1.similarity('america', j))\n",
        "for i in range(len(list5)):\n",
        "    max=list5[0]\n",
        "    if max<list5[i]:\n",
        "        max=list5[i]\n",
        "        pos=i\n",
        "print (pos)   \n",
        "print (listc[pos])  \n",
        "print (f\"Maximum similiarity is found in 'america' and  {list4[i]}\")\n",
        "print (numpy.amax(list5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1048784\n",
            "0.2934522\n",
            "Maximum similiarity is found in 'america' and  attack\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9BEjhQdBmcC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcd1a180-4845-48ba-f219-f21c107f8eab"
      },
      "source": [
        "import numpy as numpy\n",
        "\n",
        "print (numpy.argmax(listc))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcn-Z01kxwFp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f033c09-373b-4269-93e1-c9ba14703c26"
      },
      "source": [
        "print (listb[6])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "london\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5dN9N01x5lZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "254e6e86-45f5-45ad-8b31-ae40d4835ddc"
      },
      "source": [
        "print(f\"Cosine similarity between 'london' and 'india' - CBOW : \", model1.similarity('usa','india')) \n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'london' and 'india' - CBOW :  0.3322033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ1qlrkq0qIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}